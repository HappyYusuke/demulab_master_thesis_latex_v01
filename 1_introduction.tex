\noindent In recent years, there has been a strong expectation for the social implementation of autonomous mobile robots in diverse fields such as logistics, healthcare, and security. The aim is to resolve labor shortages and improve operational efficiency. For these robots to coexist with humans and perform tasks cooperatively, the "person following function"—which recognizes and follows a specific individual—is an extremely important element technology. However, in real-world environments where the surroundings change dynamically, situations frequently occur where the target person temporarily disappears from the sensor's field of view. This is often caused by other pedestrians crossing the path or obstacles blocking the view (a phenomenon known as occlusion). To ensure the continuity of tracking, "Re-identification" is indispensable. This process correctly determines whether a person who has reappeared is the original target when the robot recovers from an occlusion.

To realize person following systems in real-world environments, various approaches have been attempted so far. In methods using cameras (RGB images), systems combining deep learning-based person detection and tracking algorithms have been widely studied. Since these methods provide rich texture information, they demonstrate high identification performance under good lighting conditions. However, they strongly depend on appearance information, such as clothing, and environmental brightness. Therefore, there is a problem that recognition accuracy significantly decreases due to changes in lighting conditions, such as backlight or low light. On the other hand, methods using 2D-LiDAR allow for robust measurement that does not depend on the brightness of the environment, but the information obtained is limited to distance data on a horizontal plane. Generally, tracking is performed by clustering the cross-sections of legs or the torso. However, it is difficult to extract physical features of an individual from only the horizontal cross-sectional shape, making it hard to distinguish one person from another. Regardless of the sensor type, occlusion is unavoidable in environments with crowds or many obstacles. Tracking algorithms based only on motion models, such as Kalman filters, find it difficult to recover after losing the target due to long-term blocking or irregular movement. Therefore, establishing a robust re-identification method that can clearly distinguish the target from surrounding people upon reappearance and resume tracking has become an urgent issue in person following technology.

Therefore, the purpose of this study is to construct a system with high robustness against occlusion by introducing the re-identification model ReID3D \cite{ReID3D} into a person following system using 3D LiDAR. The novelty of this research lies in focusing on "re-identification" based on 3-dimensional point cloud information, rather than just the "detection and tracking" of the target. Many conventional studies on person following using 3D LiDAR have focused on high-precision detection or motion prediction, and there are few cases that focus on personal re-identification using point clouds. ReID3D, adopted in this study, is a person re-identification framework proposed by Guo et al. It can extract geometric features such as height, body shape, and gait from a person's 3D point cloud as high-dimensional vectors. By applying this to a person following system, we aim to realize a system that is not influenced by lighting conditions and can accurately rediscover the target even after an occlusion.

%\section{Thesis Organization}

This thesis consists of five chapters, and the outline is as follows.

In Chapter 2, we comprehensively review conventional research on person detection and person following technologies by mobile robots. Specifically, we systematically organize methods using cameras, 2D LiDAR, and 3D LiDAR, and clarify the advantages based on the characteristics of each sensor, as well as technical issues such as robustness to environmental changes. Furthermore, we explain the basic theories of the deep learning models that form the basis of this research and the system framework adopted. We also clarify the position and uniqueness of this research relative to conventional studies.

In the following Chapter 3, we describe in detail the proposed method constructed in this project to solve the issues raised in the previous chapter. We present specific algorithms for sensor fusion and data processing, as well as the architecture of the entire system. We also present the design philosophy and implementation details of a new person following approach that integrates 3D LiDAR and re-identification technology.

In Chapter 4, we discuss the experiments conducted to demonstrate the effectiveness of the proposed method. After explaining the experimental environment, the set evaluation scenarios, and the comparison methods, we quantitatively analyze the obtained experimental results. Through this, we verify that the proposed system possesses sufficient following performance and robustness in real-world environments.

Finally, in Chapter 5, we summarize the knowledge and achievements obtained in this research. We conclude on the usefulness of the proposed method revealed through a series of verifications, while also organizing the current limitations and remaining issues, and describing the prospects for future research.